# example configuration file for ceph-bluestore.fio

[global]
	debug bluestore = 0/0
	debug bluefs = 0/0
	debug bdev = 0/0
	debug rocksdb = 0/0
	# spread objects over 8 collections
	osd pool default pg num = 8
	# increasing shards can help when scaling number of collections
	osd op num shards = 5
        bluestore_shard_finishers = true
        bluestore_debug_omit_block_device_write = true
        #bluestore_max_ops=4000
        bluestore_min_alloc_size=4096
        bdev_aio_max_queue_depth=100
#        bdev_aio_poll_ms=10000

[osd]
	osd objectstore = bluestore
        bluestore_shard_finishers = true

	enable experimental unrecoverable data corrupting features = bluestore rocksdb

	# use directory= option from fio job file
	osd data = ${fio_dir}

	# log inside fio_dir
	log file = ${fio_dir}/log
